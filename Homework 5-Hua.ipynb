{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Homework 5-Hua","provenance":[{"file_id":"1irIemcomE8D4OTfhhHKEzo2e-2xYWkyj","timestamp":1644765643949}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VYovBDSbwfYD"},"source":["# 1. Receptive field and parameter count (1 point)\n","\n","Recall that the *receptive field* refers to size of the region in the input that are visible to a given activation (or neuron) in a convolutional neural network. \"Visible\" here means that the values of those inputs affect the value of the activation. In all of the following questions, assume that the input image is arbitrarily large, so you don't need to worry about boundary effects or padding.\n","\n","1. Consider a convolutional network which consists of three convolutional layers, each with a filter size of 3x3, and a stride of 1x1. What is the receptive field size of one of the activations at the final output?\n","1. What is the receptive field if the stride is 2x3 at each layer?\n","1. What is the receptive field if the stride is 2x2 at each layer, and there is a 2x2 max-pooling layer with stride 2x2 after each convolutional layer?\n","1. Assume that the input image has 3 channels, the three convolutional layers have 16, 32, and 64 channels respectively, and that there are no biases on any of the layers. How many parameters does the network have?"]},{"cell_type":"markdown","source":["### 1.1 \n","Denote the size of receptive field to be $D$. For the final output Layer $D = 1\\times 1$. After second layer $D = 3\\times 3$. After first layer $D = 5\\times 5$. At the input layer $D = 7\\times 7$."],"metadata":{"id":"AWC4keysWlUS"}},{"cell_type":"markdown","source":["### 1.2 \n","Denote the size of receptive field to be $D$. For the final output Layer $D = 1\\times 1$. After second layer $D = 3\\times 3$. After first layer $D = 7\\times 9$. At the input layer $D = 15\\times 27$."],"metadata":{"id":"-UrTAbY95U8K"}},{"cell_type":"markdown","source":["### 1.3 \n","Denote the size of receptive field to be $D$. For the Final output (After the third pooling layer), $D= 1\\times 1$. After the third conv layer, $D= 2\\times 2$. After the second pooling layer, $D= 5\\times 5$. After the second conv layer, $D= 10\\times 10$. After the first pooling layer, $D= 21\\times 21$. After the first conv layer, $D= 42\\times 42$. At the input layer, $D= 85\\times 85$."],"metadata":{"id":"8tk705rvFAke"}},{"cell_type":"markdown","source":["### 1.4\n","Assume the filter size to be $3\\times3$ and stride to be $1\\times1$, then the first layer has the parameter $3\\times 3\\times3\\times 16 = 432$. The second layer has the parameter $3\\times 3\\times 16\\times 32 = 4608$. The third layer has the parameter $3\\times 3\\times 32\\times 64 = 18432$. Thus, the final number of parameters are $432+4608+18432=23472$"],"metadata":{"id":"qKt-vkKwLdSK"}},{"cell_type":"markdown","metadata":{"id":"T8t21JGZyUr-"},"source":["# 2. CIFAR-10 classification (3 points)\n","\n","CIFAR-10 is a standard dataset where the goal is to classify 32 x 32 images into one of 10 classes. The goal of this problem is simple: build and train a convolutional neural network to perform classification on CIFAR-10. The problem is intentionally extremely open-ended! There are dozens (hundreds?) of tutorials online describing how to train a convnet on CIFAR-10 - please seek them out and make use of them. Here are some resources to get you started (which include code for loading the dataset and evaluating performance on it):\n","\n","- [CIFAR-10 example based on mxnet and our textbook](https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_computer-vision/kaggle-cifar10.ipynb)\n","- [CIFAR-10 tutorial from PyTorch](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/cifar10_tutorial.ipynb)\n","\n","You are welcome to use any other resource that you want (but please cite it!) - as I mentioned there are many, many tutorials online, and googling for help is an utterly crucial skill for a researcher! You will be graded on the final test accuracy achieved by your model:\n","\n","- 60% accuracy or higher: 2/3 points\n","- 75% accuracy or higher: 3/3 points\n","- Highest accuracy in the class: 4/3 points!\n","\n","Note that in order for us to know the final performance of your model, you will need to implement a function that computes the accuracy of your model on the test set (which appears in both of the linked tutorials above). The only rules are: You can only train your model on the CIFAR-10 training set (i.e. you can't use pre-trained models or other datasets for additional training, and you certaintly can't train on the CIFAR-10 test set!), and you must train the model on the free Colab GPU or TPU. This means you can only train the model for an hour or so! This is *much* less compute than is typically used for training CIFAR-10 models. As such, this is as much an exercise in building an accurate model as it is in building an efficient one. This is a popular game to play, and to the best of my knowledge the state-of-the-art is [this approach](https://myrtle.ai/learn/how-to-train-your-resnet/) which attains 96% accuracy in only *26 seconds* on a single GPU! (note that the final link on that page is broken; it should be [this](https://myrtle.ai/learn/how-to-train-your-resnet-8-bag-of-tricks/)).\n","\n","There are lots of things you can try to make your model more accurate and/or more efficient:\n","\n","1. Deeper models\n","1. Residual connections\n","1. [Data augmentation and normalization](https://d2l.ai/chapter_computer-vision/kaggle-cifar10.html#image-augmentation)\n","1. Regularization like dropout or weight decay\n","1. [Learning rate schedules](https://d2l.ai/chapter_optimization/lr-scheduler.html)\n","1. [Different forms of normalization](https://d2l.ai/chapter_convolutional-modern/batch-norm.html)\n","\n","Note that we haven't covered all these topics in class yet, but you should be able to get to at least 60% accuracy without applying all of these ideas - and probably 75% by tweaking around a little bit. Specifically, you should be able to get about 60% accuracy by taking the basic AlexNet architecture we discussed in class and applying it directly to CIFAR-10. And, if you're feeling adventurous, feel free to go for 96% using the aforementioned blog series! Good luck!"]},{"cell_type":"code","source":["## Train CIFAR10 with PyTorch using ResNet.\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import os\n","import argparse\n","#from utils import progress_bar\n","\n","import multiprocessing as mp"],"metadata":{"id":"7funBJsPq0lP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model\n","\n"],"metadata":{"id":"Df1q8GBlvu_8"}},{"cell_type":"code","source":["# ResNet Model\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(\n","            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2])\n"],"metadata":{"id":"19-zO7o4sxDn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up trainning environment \n","mp.set_start_method(\"fork\")\n","\n","#parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n","#parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n","#parser.add_argument('--resume', '-r', action='store_true',\n","                    #help='resume from checkpoint')\n","#args = parser.parse_args()\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","best_acc = 0  # best test accuracy\n","start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n","losses = [] # losses every time for final learning curve\n"],"metadata":{"id":"7K6X3kstrGGp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data"],"metadata":{"id":"XrQID94_vgVs"}},{"cell_type":"code","source":["# Data\n","print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(\n","    root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(\n","    root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size=100, shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer',\n","           'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6WPuy5TsOTd","executionInfo":{"status":"ok","timestamp":1644871457073,"user_tz":300,"elapsed":2038,"user":{"displayName":"Hanqi Hua","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06347690475984403200"}},"outputId":"bf697559-a162-423c-f985-e4ee18ce6aa5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==> Preparing data..\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["# set up the model\n","print('==> Building model..')\n","net = ResNet18()\n","net = net.to(device)\n","if device == 'cuda':\n","    net = torch.nn.DataParallel(net)\n","    cudnn.benchmark = True\n","\n","#if args.resume:\n","    # Load checkpoint.\n","    #print('==> Resuming from checkpoint..')\n","    #assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n","    #checkpoint = torch.load('./checkpoint/ckpt.pth')\n","    #net.load_state_dict(checkpoint['net'])\n","    #best_acc = checkpoint['acc']\n","    #start_epoch = checkpoint['epoch']\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.1,\n","                      momentum=0.9, weight_decay=5e-4)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JA5UP7p7sOF7","executionInfo":{"status":"ok","timestamp":1644871462207,"user_tz":300,"elapsed":2845,"user":{"displayName":"Hanqi Hua","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06347690475984403200"}},"outputId":"fb2a48f4-4c41-481a-81a5-cc3028208df7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==> Building model..\n"]}]},{"cell_type":"markdown","source":["## Training and Testing"],"metadata":{"id":"gUiQtM-0vUAD"}},{"cell_type":"code","source":["# Training\n","def train(epoch):\n","    print('\\nEpoch: %d' % epoch)\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    global losses\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","        if batch_idx == 390:\n","          losses.append(train_loss/(batch_idx+1))\n","          print('Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","          % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","          #progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","                     #% (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","\n","\n","def test(epoch):\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","            if batch_idx == 99:\n","              print('Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","              % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","              #progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","                         #% (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","\n","    # Save checkpoint.\n","    acc = 100.*correct/total\n","    if acc > best_acc:\n","        print('Saving..')\n","        state = {\n","            'net': net.state_dict(),\n","            'acc': acc,\n","            'epoch': epoch,\n","        }\n","        if not os.path.isdir('checkpoint'):\n","            os.mkdir('checkpoint')\n","        torch.save(state, './checkpoint/ckpt.pth')\n","        best_acc = acc"],"metadata":{"id":"nO23GqROscz7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(start_epoch, start_epoch+50):\n","    train(epoch)\n","    test(epoch)\n","    scheduler.step()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LtvtM8fTsfCW","outputId":"ba9fe2ea-d9fc-4776-ea67-a291a3bfd6f9","executionInfo":{"status":"ok","timestamp":1644876108101,"user_tz":300,"elapsed":4641669,"user":{"displayName":"Hanqi Hua","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06347690475984403200"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch: 0\n","Loss: 1.968 | Acc: 31.054% (15527/50000)\n","Loss: 1.570 | Acc: 41.480% (4148/10000)\n","Saving..\n","\n","Epoch: 1\n","Loss: 1.438 | Acc: 47.398% (23699/50000)\n","Loss: 1.308 | Acc: 52.520% (5252/10000)\n","Saving..\n","\n","Epoch: 2\n","Loss: 1.172 | Acc: 57.768% (28884/50000)\n","Loss: 1.138 | Acc: 59.800% (5980/10000)\n","Saving..\n","\n","Epoch: 3\n","Loss: 0.961 | Acc: 65.942% (32971/50000)\n","Loss: 0.965 | Acc: 66.750% (6675/10000)\n","Saving..\n","\n","Epoch: 4\n","Loss: 0.788 | Acc: 72.432% (36216/50000)\n","Loss: 0.792 | Acc: 72.590% (7259/10000)\n","Saving..\n","\n","Epoch: 5\n","Loss: 0.678 | Acc: 76.528% (38264/50000)\n","Loss: 0.646 | Acc: 77.670% (7767/10000)\n","Saving..\n","\n","Epoch: 6\n","Loss: 0.603 | Acc: 78.968% (39484/50000)\n","Loss: 0.656 | Acc: 76.900% (7690/10000)\n","\n","Epoch: 7\n","Loss: 0.566 | Acc: 80.448% (40224/50000)\n","Loss: 0.791 | Acc: 74.650% (7465/10000)\n","\n","Epoch: 8\n","Loss: 0.539 | Acc: 81.490% (40745/50000)\n","Loss: 0.647 | Acc: 77.750% (7775/10000)\n","Saving..\n","\n","Epoch: 9\n","Loss: 0.505 | Acc: 82.584% (41292/50000)\n","Loss: 0.569 | Acc: 80.690% (8069/10000)\n","Saving..\n","\n","Epoch: 10\n","Loss: 0.480 | Acc: 83.540% (41770/50000)\n","Loss: 0.640 | Acc: 78.630% (7863/10000)\n","\n","Epoch: 11\n","Loss: 0.467 | Acc: 84.012% (42006/50000)\n","Loss: 0.658 | Acc: 78.070% (7807/10000)\n","\n","Epoch: 12\n","Loss: 0.452 | Acc: 84.552% (42276/50000)\n","Loss: 0.539 | Acc: 81.820% (8182/10000)\n","Saving..\n","\n","Epoch: 13\n","Loss: 0.433 | Acc: 85.204% (42602/50000)\n","Loss: 0.712 | Acc: 76.420% (7642/10000)\n","\n","Epoch: 14\n","Loss: 0.427 | Acc: 85.272% (42636/50000)\n","Loss: 0.483 | Acc: 83.660% (8366/10000)\n","Saving..\n","\n","Epoch: 15\n","Loss: 0.415 | Acc: 85.780% (42890/50000)\n","Loss: 0.553 | Acc: 82.100% (8210/10000)\n","\n","Epoch: 16\n","Loss: 0.410 | Acc: 86.014% (43007/50000)\n","Loss: 0.571 | Acc: 80.980% (8098/10000)\n","\n","Epoch: 17\n","Loss: 0.396 | Acc: 86.444% (43222/50000)\n","Loss: 0.636 | Acc: 79.000% (7900/10000)\n","\n","Epoch: 18\n","Loss: 0.394 | Acc: 86.656% (43328/50000)\n","Loss: 0.689 | Acc: 79.260% (7926/10000)\n","\n","Epoch: 19\n","Loss: 0.389 | Acc: 86.720% (43360/50000)\n","Loss: 0.518 | Acc: 82.980% (8298/10000)\n","\n","Epoch: 20\n","Loss: 0.382 | Acc: 87.032% (43516/50000)\n","Loss: 0.595 | Acc: 81.580% (8158/10000)\n","\n","Epoch: 21\n","Loss: 0.377 | Acc: 87.258% (43629/50000)\n","Loss: 0.486 | Acc: 83.910% (8391/10000)\n","Saving..\n","\n","Epoch: 22\n","Loss: 0.370 | Acc: 87.480% (43740/50000)\n","Loss: 0.713 | Acc: 77.990% (7799/10000)\n","\n","Epoch: 23\n","Loss: 0.374 | Acc: 87.126% (43563/50000)\n","Loss: 0.441 | Acc: 85.290% (8529/10000)\n","Saving..\n","\n","Epoch: 24\n","Loss: 0.367 | Acc: 87.478% (43739/50000)\n","Loss: 0.483 | Acc: 84.240% (8424/10000)\n","\n","Epoch: 25\n","Loss: 0.358 | Acc: 87.842% (43921/50000)\n","Loss: 0.431 | Acc: 85.840% (8584/10000)\n","Saving..\n","\n","Epoch: 26\n","Loss: 0.353 | Acc: 87.958% (43979/50000)\n","Loss: 0.600 | Acc: 80.780% (8078/10000)\n","\n","Epoch: 27\n","Loss: 0.355 | Acc: 87.972% (43986/50000)\n","Loss: 0.627 | Acc: 80.040% (8004/10000)\n","\n","Epoch: 28\n","Loss: 0.351 | Acc: 88.062% (44031/50000)\n","Loss: 0.492 | Acc: 83.670% (8367/10000)\n","\n","Epoch: 29\n","Loss: 0.346 | Acc: 88.010% (44005/50000)\n","Loss: 0.583 | Acc: 80.650% (8065/10000)\n","\n","Epoch: 30\n","Loss: 0.346 | Acc: 88.258% (44129/50000)\n","Loss: 0.448 | Acc: 85.040% (8504/10000)\n","\n","Epoch: 31\n","Loss: 0.344 | Acc: 88.232% (44116/50000)\n","Loss: 0.605 | Acc: 80.810% (8081/10000)\n","\n","Epoch: 32\n","Loss: 0.333 | Acc: 88.810% (44405/50000)\n","Loss: 0.538 | Acc: 83.010% (8301/10000)\n","\n","Epoch: 33\n","Loss: 0.334 | Acc: 88.628% (44314/50000)\n","Loss: 0.592 | Acc: 80.470% (8047/10000)\n","\n","Epoch: 34\n","Loss: 0.337 | Acc: 88.480% (44240/50000)\n","Loss: 0.394 | Acc: 86.790% (8679/10000)\n","Saving..\n","\n","Epoch: 35\n","Loss: 0.332 | Acc: 88.716% (44358/50000)\n","Loss: 0.459 | Acc: 84.760% (8476/10000)\n","\n","Epoch: 36\n","Loss: 0.326 | Acc: 88.960% (44480/50000)\n","Loss: 0.502 | Acc: 83.650% (8365/10000)\n","\n","Epoch: 37\n","Loss: 0.334 | Acc: 88.646% (44323/50000)\n","Loss: 0.437 | Acc: 85.670% (8567/10000)\n","\n","Epoch: 38\n","Loss: 0.325 | Acc: 88.948% (44474/50000)\n","Loss: 0.583 | Acc: 81.100% (8110/10000)\n","\n","Epoch: 39\n","Loss: 0.327 | Acc: 88.872% (44436/50000)\n","Loss: 0.451 | Acc: 84.910% (8491/10000)\n","\n","Epoch: 40\n","Loss: 0.323 | Acc: 89.008% (44504/50000)\n","Loss: 0.564 | Acc: 82.280% (8228/10000)\n","\n","Epoch: 41\n","Loss: 0.321 | Acc: 89.068% (44534/50000)\n","Loss: 0.448 | Acc: 84.510% (8451/10000)\n","\n","Epoch: 42\n","Loss: 0.323 | Acc: 88.952% (44476/50000)\n","Loss: 0.648 | Acc: 79.520% (7952/10000)\n","\n","Epoch: 43\n","Loss: 0.306 | Acc: 89.650% (44825/50000)\n","Loss: 0.467 | Acc: 84.850% (8485/10000)\n","\n","Epoch: 44\n","Loss: 0.314 | Acc: 89.432% (44716/50000)\n","Loss: 0.383 | Acc: 87.030% (8703/10000)\n","Saving..\n","\n","Epoch: 45\n","Loss: 0.312 | Acc: 89.492% (44746/50000)\n","Loss: 0.413 | Acc: 86.540% (8654/10000)\n","\n","Epoch: 46\n","Loss: 0.308 | Acc: 89.552% (44776/50000)\n","Loss: 0.634 | Acc: 80.340% (8034/10000)\n","\n","Epoch: 47\n","Loss: 0.311 | Acc: 89.362% (44681/50000)\n","Loss: 0.476 | Acc: 84.870% (8487/10000)\n","\n","Epoch: 48\n","Loss: 0.299 | Acc: 89.940% (44970/50000)\n","Loss: 0.631 | Acc: 80.550% (8055/10000)\n","\n","Epoch: 49\n","Loss: 0.300 | Acc: 89.816% (44908/50000)\n","Loss: 0.403 | Acc: 86.530% (8653/10000)\n"]}]},{"cell_type":"markdown","source":["## Result:\n","After 50 epochs of training, we have the testing accuracy to be 86.530%. \n","\n","Below is the the learning curve (Training loss vs Epoch). "],"metadata":{"id":"qieBh_7yu3zo"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.plot(losses)\n","plt.xlabel('epoch')\n","plt.ylabel('Training loss')\n","plt.title('Loss vs. No. of epochs')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"6GgSp4uARjWD","executionInfo":{"status":"ok","timestamp":1644876631974,"user_tz":300,"elapsed":291,"user":{"displayName":"Hanqi Hua","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06347690475984403200"}},"outputId":"109b27a9-028d-47ee-f729-7fc87064779c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxddX3/8dd79n2SmcwMWcjGooQAEaYhIggqKrYutbYqisX+9Ee1rtX+WrcWxfr7Wdsq2lqVKlWr4k5FxCUiqxpkgqwJSwgBss4kk2QmmX3m8/vjnAmXcGdys9y5s7yfj8d53Hu/Z7mfM8v93O/3e873q4jAzMzsYEWFDsDMzCYnJwgzM8vKCcLMzLJygjAzs6ycIMzMLCsnCDMzy8oJwmwKkNQi6VZJ3ZL+tdDxAEjaJOnCQsdh+eMEYXk1nT5EJH1UUkh6bUZZSVq2OM9vfxmwE6iLiPfn+b3MACcIs8PVCXxMUvEEv+8iYF34zlabQE4QVhCSyiVdKWlrulwpqTxdN0fS9ZL2SOqUdJukonTd30nakja1PCTpRVmOfbak7Zkf4pJeLene9PlKSW2SuiTtkPTpwwj9Z8AAcMkY51Uv6euSOiQ9Lukjo7Hn8DM5R9Kdkvamj+ek5V8FLgX+VtK+bDWy9Of5L5KeSM/pi5Iq03UXSNos6UOSdqa1ujfmGrOk/y1pffozXyfpzIy3XiHp3jTm70iqSPcZ83doU4d/YVYoHwZWASuAM4CVwEfSde8HNgNNQAvwISAkPQt4J/AHEVELvBTYdPCBI+IOYD/wwoziNwDfSp9/FvhsRNQBJwDfPYy4A/h74HJJpVnW/xtQDywFzgf+HPiLQx1UUgPwE+BzQCPwaeAnkhoj4s3AN4FPRURNRPwyyyE+CZxM8vM8EZgP/EPG+uOAOWn5pcBV6c9z3Jgl/Rnw0bSsDnglsCvjuK8FLgKWAKcDb07Ls/4OD/VzsMnFCcIK5Y3AFRHRHhEdwMeAN6XrBoG5wKKIGIyI29KmlWGgHFgmqTQiNkXEo2Mc/xrgYgBJtcAfpmWjxz9R0pyI2BcRaw4n8Ii4DugA3ppZntZYXg98MCK6I2IT8K8Z5zWePwIeiYj/joihiLgGeBB4xaF2lCSSPoq/jojOiOgG/m8aS6a/j4j+iLiFJBm9NoeY30qSmO6MxIaIeDzjmJ+LiK0R0Qn8mCRBwdi/Q5tCnCCsUOYBmR80j6dlAP8MbAB+IWmjpA8ARMQG4L0k32jbJX1b0jyy+xbwJ2mz1Z8Ad2V8sL2F5Nv2g2lTzsuPIP6PkNSCKjLK5gClWc5rfg7HO/jncTj7NgFVwNq0SWcPSVNYU8Y2uyNi/0HHnpdDzMcDYyVhgO0Zz3uAmvR51t+hTS1OEFYoW0k6XkctTMtIv8m+PyKWkjRpvG+0ryEivhUR56b7BvBP2Q4eEetIPuhextObl4iIRyLiYqA53f/7kqoPJ/iIWE3yAfhXGcU7Sb45H3xeW3I45ME/j8PZdyfQC5waEbPSpT4iajK2mX3QOY7+vA8V85MkzXCHZbzfoU0dThA2EUolVWQsJSTNPR+R1CRpDkl7+TcAJL1c0olp08lekqalEUnPkvTCtFbQR/KhODLO+34LeA/wfOB7o4WSLpHUFBEjwJ60eLzjjOXDwN+OvoiIYZL+jE9IqpW0CHjf6Hkdwg3AyZLekF46+zpgGXD9oXZMz+M/gc9IagaQNF/SSw/a9GOSyiSdB7wc+F4OMX8Z+BtJZylxYrrNuMb6Hebwc7BJxAnCJsINJB/mo8tHgX8E2oB7gfuAu9IygJOAXwL7gN8C/xERN5H0P3yS5FvvdpIawAfHed9rSDpdfxUROzPKLwIekLSPpMP69RHRC5BeJXReLicVEb8GfndQ8btIOsg3AreTJKmr02N/SNJPxzjWLpIP7feTdAL/LfDyg+Iez9+R1GjWSOoi+fk9K2P9dmA3Sa3hm8DbIuLBQ8UcEd8DPpGWdQP/AzTkEM9Yv0ObQuR+I7PpTdIFwDciYkGhY7GpxTUIMzPLygnCzMyychOTmZll5RqEmZllVVLoAI6lOXPmxOLFiwsdhpnZlLF27dqdEdGUbd20ShCLFy+mra2t0GGYmU0Zkg6+g/8ANzGZmVlWeUsQko6XdFM6PPADkt6TZRtJ+pykDemQwWdmrLtU0iPpcmm+4jQzs+zy2cQ0BLw/Iu5KR9NcK2l1OkbOqJeR3HF5EnA28AXg7HTo48uBVpLxdtZKui4iducxXjMzy5C3GkREbIuIu9Ln3cB6njky5auAr6fDCK8BZkmaSzLO/+p06OLdwGqS4RHMzGyCTEgfhJL5ep8D3HHQqvkko0WO2pyWjVWe7diXKZkdrK2jo+NYhWxmNuPlPUFIqgF+ALw3IrqO9fEj4qqIaI2I1qamrFdqmZnZEchrgkinZPwB8M2I+GGWTbaQTEgyakFaNla5mZlNkHxexSTgK8D6iBhrUvjrgD9Pr2ZaBeyNiG3Az4GXSJotaTbwkrTsmBsZCf7txke45WE3T5mZZcrnVUzPI5nX9j5Jd6dlHyKZrYqI+CLJPAF/SDKOfQ/pROkR0Snp48Cd6X5XpHPeHnNFReKq2zbymjMXcP7JbqIyMxuVtwQREbcDOsQ2AbxjjHVXk05akm/NteXs6OqbiLcyM5syfCc10FxbQXt3f6HDMDObVJwggJa6ctq7XYMwM8vkBAE011Wwo6sfz41hZvYUJwiSPoiBoRG6eocKHYqZ2aThBEFSgwDczGRmlsEJgqQGAbCjyx3VZmajnCCAFtcgzMyewQmCp2oQvtTVzOwpThBAdXkJ1WXFvlnOzCyDE0Sqpc43y5mZZXKCSDXVltPhTmozswOcIFLNdRXscCe1mdkBThCpltpy2n03tZnZAU4Qqea6cnoHh9nX77upzczACeKA5trkXgjfLGdmlnCCSDXXjd4L4X4IMzNwgjhgtAbR4UtdzcwAJ4gDRmsQvlnOzCzhBJGqLS+hsrSYdvdBmJkBThAHSKK5rtx3U5uZpZwgMjTXlruJycwslbcEIelqSe2S7h9j/f+RdHe63C9pWFJDum6TpPvSdW35ivFgzXUV7qQ2M0vlswbxVeCisVZGxD9HxIqIWAF8ELglIjozNnlBur41jzE+jWsQZmZPyVuCiIhbgc5Dbpi4GLgmX7Hkqrm2gv0Dw+z33dRmZoXvg5BURVLT+EFGcQC/kLRW0mWH2P8ySW2S2jo6Oo4qlpY6TxxkZjaq4AkCeAXw64Oal86NiDOBlwHvkPT8sXaOiKsiojUiWpuamo4qkKeG23Azk5nZZEgQr+eg5qWI2JI+tgPXAisnIhDXIMzMnlLQBCGpHjgf+FFGWbWk2tHnwEuArFdCHWujNYh21yDMzCjJ14ElXQNcAMyRtBm4HCgFiIgvppu9GvhFROzP2LUFuFbSaHzfioif5SvOTHWVJZSVFLkGYWZGHhNERFycwzZfJbkcNrNsI3BGfqIanyRa6spdgzAzY3L0QUwqzbUVrkGYmeEE8Qy+Wc7MLOEEcZCWOtcgzMzACeIZmmrL6e4bondguNChmJkVlBPEQZprPfWomRk4QTxDS116L4SbmcxshnOCOMjo1KOeWc7MZjoniIN4PCYzs4QTxEFmV5VSWiw3MZnZjOcEcRBJ6c1yrkGY2czmBJFFU225+yDMbMZzgsiipa7cNQgzm/GcILLweExmZk4QWTXXlrOnZ5C+Qd9NbWYzlxNEFqM3y3W4FmFmM5gTRBZNdR5uw8zMCSKLlgNTj7oGYWYzlxNEFgeG23ATk5nNYE4QWTRUlVFSJA+3YWYzmhNEFkVFSm6Wcw3CzGawvCUISVdLapd0/xjrL5C0V9Ld6fIPGesukvSQpA2SPpCvGMfT7ARhZjNcPmsQXwUuOsQ2t0XEinS5AkBSMfB54GXAMuBiScvyGGdWTbUVtLuJycxmsLwliIi4Feg8gl1XAhsiYmNEDADfBl51TIPLQTLchmsQZjZzFboP4rmS7pH0U0mnpmXzgSczttmclk2o5toKOvcPMDA0MtFvbWY2KRQyQdwFLIqIM4B/A/7nSA4i6TJJbZLaOjo6jllwo5e6duxzLcLMZqaCJYiI6IqIfenzG4BSSXOALcDxGZsuSMvGOs5VEdEaEa1NTU3HLL6WA1OPuh/CzGamgiUIScdJUvp8ZRrLLuBO4CRJSySVAa8Hrpvo+EanHnU/hJnNVCX5OrCka4ALgDmSNgOXA6UAEfFF4E+Bt0saAnqB10dEAEOS3gn8HCgGro6IB/IV51iaa12DMLOZLW8JIiIuPsT6fwf+fYx1NwA35COuXDXWlFMk1yDMbOYq9FVMk1ZxkZhT46lHzWzmcoIYR3NdOdvdxGRmM5QTxDgWN1bzaMe+QodhZlYQThDjWD6/ns27e9nTM1DoUMzMJpwTxDhOm18PwP1bugociZnZxHOCGMep8+oAuH/r3gJHYmY28ZwgxjGrqowFsyu5b4sThJnNPE4Qh3Da/HoecIIwsxnICeIQls+vZ9OuHrr6BgsdipnZhDpkgpD0PEnV6fNLJH1a0qL8hzY5LE87qh9wR7WZzTC51CC+APRIOgN4P/Ao8PW8RjWJjHZUP+COajObYXJJEEPpIHqvAv49Ij4P1OY3rMljTk05c+sr3FFtZjNOLoP1dUv6IHAJ8HxJRaSjss4Uy+fXc78ThJnNMLnUIF4H9ANviYjtJBP4/HNeo5pkls+rZ+PO/ezrHyp0KGZmEyaXBNENfDYibpN0MrACuCa/YU0upy2oIwLWb3NHtZnNHLkkiFuBcknzgV8AbwK+ms+gJpvl85Irme7b7GYmM5s5ckkQioge4E+A/4iIPwOW5zesyaW5roLm2nIPuWFmM0pOCULSc4E3Aj85jP2mleXz630vhJnNKLl80L8X+CBwbUQ8IGkpcFN+w5p8ls+r45H2bnoHhgsdipnZhDjkZa4RcQtwi6QaSTURsRF4d/5Dm1yWz69nJGD99i7OXDi70OGYmeVdLkNtnCbp98ADwDpJayWdmv/QJpflB+aGcD+Emc0MuTQxfQl4X0QsioiFJMNt/OehdpJ0taR2SfePsf6Nku6VdJ+k36RDeYyu25SW3y2pLdeTyae59RU0Vpc5QZjZjJFLgqiOiAN9DhFxM1Cdw35fBS4aZ/1jwPkRcRrwceCqg9a/ICJWRERrDu+Vd5I4dX4997mj2sxmiFwSxEZJfy9pcbp8BNh4qJ0i4lagc5z1v4mI3enLNSR3aE9qy+fV8ciObvoG3VFtZtNfLgnifwFNwA/TpSktO5beAvw043UAv0j7Oy4bb0dJl0lqk9TW0dFxjMN6utPm1zM0Ejy8ozuv72NmNhnkchXTbvJ41ZKkF5AkiHMzis+NiC2SmoHVkh5MayTZ4ruKtHmqtbU18hUnPNVRfd+WvZy+YFY+38rMrODGTBCSfkzyTT6riHjl0b65pNOBLwMvi4hdGcfekj62S7oWWEky5EdBLZhdSX1lKfe7H8LMZoDxahD/ks83lrSQpMnqTRHxcEZ5NVAUEd3p85cAV+QzllxJYvn8Ol/JZGYzwpgJIr1B7ohJuga4AJgjaTNwOek8EhHxReAfgEbgPyRBMjFRK9ACXJuWlQDfioifHU0sx9LyefX81683MTA0QlnJjBtxxMxmkFwmDDoiEXHxIda/FXhrlvKNwBnP3GNyWD6/noHhER5p7+bUdJRXM7PpyF+BD5PvqDazmcIJ4jAtaqiitrzEHdVmNu0dsolpjKuZ9gJtwJcioi8fgU1WRUVi2bw67nMNwsymuZzupAb2kYy/9J9AF8k0pCeTw5hM09Fp8+tZv62L/iHfUW1m01cuCeKciHhDRPw4XS4B/iAi3gGcmef4JqU/WNJA/9AI93oKUjObxnJJEDXpPQvAgfsXatKXA3mJapJbubgBgDs27jrElmZmU1cuCeL9wO2SbpJ0M3Ab8DfpTWxfy2dwk9Xs6jKefVwtazaOORahmdmUl8tYTDdIOgl4dlr0UEbH9JV5i2ySW7W0kW/f+YRvmDOzaSvXT7azgFNJbmB7raQ/z19IU8OqpQ30DY5w35Y9hQ7FzCwvcrnM9b+BE4C7gdHLdgL4eh7jmvRWLmkEYM3GTs5a1FDgaMzMjr1chtpoBZZFRF6H0p5qGqrLeFZLLWs27uIdLzix0OGYmR1zuTQx3Q8cl+9ApqJVSxto27SbweGRQodiZnbM5ZIg5gDrJP1c0nWjS74DmwpWLW2kd3DY90OY2bSUSxPTR/MdxFS1cknS97Bm4y7OWjS7wNGYmR1buVzmelTzQkxnjTXlnNxSwx2PdfKOFxQ6GjOzY2vMJiZJt6eP3ZK6MpZuSR7KNLVqaSNtmzrdD2Fm086YCSIizk0fayOiLmOpjYi6iQtxcjt7SSM9A8Me3dXMpp2cbpSTVCxpnqSFo0u+A5sqzl46Oi6Th90ws+nlkAlC0ruAHcBq4Cfpcn2e45oy5tSUc2JzDWs8cJ+ZTTO5XMX0HuBZEeFPwDGsWtrAtXdtYWh4hJJij8tkZtNDLp9mT5LMIGdjWLW0kf0Dw9y/1X33ZjZ95Dqj3M2SPijpfaNLLgeXdLWkdkn3j7Fekj4naYOkeyWdmbHuUkmPpMuluZ1OYWTeD2FmNl3kkiCeIOl/KANqM5ZcfBW4aJz1LwNOSpfLgC8ASGoALgfOBlYCl0uatHeiNddWcEJTtROEmU0rudwo97EjPXhE3Cpp8TibvAr4ejoQ4BpJsyTNBS4AVkdEJ4Ck1SSJ5pojjSXfVi1t5Ed3b3U/hJlNG+PdKHdl+vjjzDGYjvFYTPNJ+jhGbU7LxirPFudlktoktXV0dByjsA7f2Usb2dc/xAPuhzCzaWK8GsR/p4//MhGBHKmIuAq4CqC1tbVgQ5KvyuiHOOP4WYUKw8zsmBkzQUTE2vQxn2MxbQGOz3i9IC3bQtLMlFl+cx7jOGrNdRUsnVPNHY918pfnn1DocMzMjlouN8qdJOn7ktZJ2ji6HKP3vw748/RqplXA3ojYBvwceImk2Wnn9EvSsknt7KWN3PlYJ0Mel8nMpoFcelP/i+TqoiHgBSRTjX4jl4NLugb4LfAsSZslvUXS2yS9Ld3kBpLLaDcA/wn8FUDaOf1x4M50uWK0w3oyW7W0ge7+Ie71uExmNg3kcid1ZUTcKEkR8TjwUUlrgX841I4RcfEh1gfwjjHWXQ1cnUN8k8b5JzdRXCR+tb6dMxdO2qtyzcxykksNol9SEfCIpHdKejVQk+e4pqRZVWW0LprNL9fvKHQoZmZHLZcE8R6gCng3cBZwCTCp72wupBcva+HB7d082dlT6FDMzI7KuAlCUjHwuojYFxGbI+IvIuI1EbFmguKbcl50SguAaxFmNuWNd6NcSUQMA+dOYDxT3pI51ZzYXOMEYWZT3nid1L8DzgR+n945/T1g/+jKiPhhnmObsi48pYUv37aRvb2D1FeWFjocM7MjkksfRAWwC3gh8HLgFemjjeHFy5oZGgluebhwQ3+YmR2t8WoQzemw3vcDAShjXcGGtJgKVhw/m4bqMm5cv4NXnjGv0OGYmR2R8RJEMcnlrMqyzgliHMVF4oXPbuYXD2xncHiEUo/uamZT0HgJYltEXDFhkUwzF57SwvfXbubOTZ2cc8KcQodjZnbYxvtqm63mYDk676Q5lJUU8ct17YUOxczsiIyXIF40YVFMQ9XlJTzvhEZWr99OMqKImdnUMmaCmAqD4012Fy5r4cnOXh5p31foUMzMDpt7T/PoRc9O7qpevc43zZnZ1OMEkUfH1Vdw+oJ631VtZlOSE0SeXXhKC3c/uYeO7v5Ch2JmdlicIPLswlNaiICbHvTVTGY2tThB5Nkpc2uZP6uS1W5mMrMpxgkizyRx4SnN3PZIB32Dw4UOx8wsZ04QE+DCZS30DY548D4zm1KcICbA2UsaOa6ugqtvf6zQoZiZ5SyvCULSRZIekrRB0geyrP+MpLvT5WFJezLWDWesuy6fceZbWUkRbz1vCXc81snax3cXOhwzs5zkLUGk05V+HngZsAy4WNKyzG0i4q8jYkVErAD+DcichKh3dF1EvDJfcU6Ui1cuZHZVKV+4eUOhQzEzy0k+axArgQ0RsTEiBoBvA68aZ/uLgWvyGE9BVZeX8OZzlvDL9e08uL2r0OGYmR1SPhPEfODJjNeb07JnkLQIWAL8KqO4QlKbpDWS/nisN5F0WbpdW0fH5O4EvvScRVSXFfOFmx8tdChmZoc0WTqpXw98PyIyrwNdFBGtwBuAKyWdkG3HiLgqIlojorWpqWkiYj1is6rKeMPZC/nxPVt5YldPocMxMxtXPhPEFuD4jNcL0rJsXs9BzUsRsSV93AjcDDzn2Ic48d563lJKior40q2uRZjZ5JbPBHEncJKkJZLKSJLAM65GkvRsYDbw24yy2ZLK0+dzgOcB6/IY64RpqavgNWct4Httm2nv6it0OGZmY8pbgoiIIeCdwM+B9cB3I+IBSVdIyrwq6fXAt+Pps+qcArRJuge4CfhkREyLBAHwtvOXMjQywld8X4SZTWKaTrOdtba2RltbW6HDyMm7r/k9N67fwW8+8CLqq0oLHY6ZzVCS1qb9vc8wWTqpZ5y3X3AC+weG+dpvNxU6FDOzrJwgCuSUuXW88NnN/NevH6NnYKjQ4ZiZPYMTRAG94wUnsLtnkG+ueaLQoZiZPYMTRAGdtaiBC57VxL+ufohHO/YVOhwzs6dxgiiwf3rN6VSUFvPX37mbweGRQodjZnaAE0SBtdRV8Mk/OY17N+/lczc+UuhwzMwOcIKYBC5aPpc/PWsBn79pA2sf7yx0OGZmgBPEpHH5K5Yxf3Yl7/3O3ezr91VNZlZ4ThCTRG1FKZ957Qq27O7lY9c9UOhwzMycICaT1sUN/NUFJ/K9tZv56X3bCh2Omc1wThCTzHsuPInTF9TzwWvvY4cH8zOzAnKCmGRKi4v4zOtW0Dc4zF/+91q27OktdEhmNkM5QUxCJzTV8JnXruCRHd1cdOWt/OjusabRMDPLHyeISeplp83lhvecx0nNNbzn23fz7mt+z96ewUKHZWYziBPEJLaosZrv/uVzef+LT+aG+7Zx0Wdv5TeP7ix0WGY2QzhBTHIlxUW860Un8YO3n0NlaTFv/PIdfPz6deztdW3CzPLLCWKKOOP4WVz/7nN549kL+crtj/H8T93EF295lN6B4UKHZmbTlBPEFFJVVsI//vFpXP+uc3nOwll88qcPcsG/3MQ373jcA/2Z2THnBDEFLZ9fz1f/YiXfuWwVC2ZX8eFr7+fFn76F6+7ZynSaQtbMCssJYgo7e2kj33/bc/nKpa1UlBbz7mt+zyVfuYMndvUUOjQzmwacIKY4SbzolBZuePd5fOLVy7nnyb289Mpb+crtjzE84tqEmR25vCYISRdJekjSBkkfyLL+zZI6JN2dLm/NWHeppEfS5dJ8xjkdFBWJN569iNXvez7PPaGRj1+/jj/74m94ZEd3oUMzsylK+WqzllQMPAy8GNgM3AlcHBHrMrZ5M9AaEe88aN8GoA1oBQJYC5wVEbvHe8/W1tZoa2s7lqcxJUUE192zlY9e9wD7+4d51wtP5C/PP4GyElcYzezpJK2NiNZs6/L5ibES2BARGyNiAPg28Koc930psDoiOtOksBq4KE9xTjuSeNWK+ax+3/m85NQW/nX1wzz/Uzfx5ds2eq4JM8tZPhPEfODJjNeb07KDvUbSvZK+L+n4w9wXSZdJapPU1tHRcSzinjbm1JTz7284k2+85WyWzKnmH3+ynud98ld8+hcPsWtff6HDM7NJrtBtDj8GFkfE6SS1hK8d7gEi4qqIaI2I1qampmMe4HRw7klzuOayVVz7V+ewamkDn/vVBp73T7/i8h/dz7qtXYy4M9vMsijJ47G3AMdnvF6Qlh0QEbsyXn4Z+FTGvhcctO/NxzzCGeY5C2fzpTe1sqG9my/dspFv3vEEX/vt49RVlLBySQMrlzRw9pJGTp1XR0lxob87mFmh5bOTuoSkk/pFJB/4dwJviIgHMraZGxHb0uevBv4uIlalndRrgTPTTe8i6aTuHO893Ul9eNq7+rh9w07u2NjJ7zZ18tjO/QBUlxXTuriB809u4oJnNbFkTjWSChytmeXDeJ3UeUsQ6Rv/IXAlUAxcHRGfkHQF0BYR10n6f8ArgSGgE3h7RDyY7vu/gA+lh/pERPzXod7PCeLotHf18btNndyxsZNfP7qTjR1Jwji+oTJJFic389wTGqkuz2fF08wmUsESxERzgji2nuzs4eaHO7jloQ5+8+hOegaGKSsp4sXLWnjNmfM576QmSt0UZTalOUHYUesfGmbtpt387IHt/PierezuGaSxuoxXrpjHa85cwKnz6twMZTYFOUHYMTUwNMItD3fww7s2c+P6dgaGRzihqZpnH1fHcfUVzK2vYG59JXNnVTCvvpKWunInD7NJarwE4cZkO2yjzUwvXtbC3p5Brr9vKz9/YAfrt3Vx44M76Bt8+tDjs6tKOWvRbM5a1MBZi2Zz+oJ6KkqLCxS9meXKNQg7piKCvb2DbN3Tx/auXrbs7uWezXu56/HdbEyvkiotFqfOq+eUubUcV/dUTeO4+grmzaqgqszfW8wmimsQNmEkMauqjFlVZSybVwfAm9J1u/b1c9cTe1j7+G7WPt7J6nU72Llv4BnHaKot5+wlDaxa2siqpY2c0OTLbM0KwQnCJkxjTfmBpqlRfYPDtHf1s21vL9v29rFtbx8Pbu9izcZdXH/vNiBJGKuWNnLWwlnMri6jtqKE6rISaipKqC0vpaaihPrKUoqLnETMjiUnCCuoitJiFjZWsbCx6mnlEcGmXT2s2biLNRt38dtHd/Hje7aOeRwJZleV0VhdRmNNGY3V5TTWlDG3vpJFjVUsbKhiUWMVtRWl+T4ls2nDCcImJUksmVPNkjnVXLxyIRFBx75+uvuG2Nc3xL7+Ibr7htjfP0R33yCdPYPs2tfPrn0DdO4fYP32LnZ299PV9/TRaxury1jYWMX8WZU01ZYnS03y2FxbQUtdOQ3VZW7SMsMJwqYISTTXVtBce3j7dfcN8viuHp7o7BRgadwAAAutSURBVEkf9/P4rh7Wbe2ivbs/6/DnNeUlLGqsSmse1SxurOK4+gq6+4bY3TPArn0D7O5JEtHe3kEaqss4fnYVxzdUpo9VzK2v8HhWNuU5Qdi0VltRyvL59SyfX591fc/AEDu7B2jv7qOju5+te/t4Ytd+Hu/s4cFt3axet4PB4Wde6VdfWUpDdRl1laU8tnM/19+77WlTvBYXiYUNVZzUXMNJLTWc3FLLic01nNBU40t8bcpwgrAZraqshIWNJc/oAxk1PBJs3dNLe3cfdRWlzK4uY1Zl6TNqB4PDI2zf28eTnT08uTupsWzs2M/DO7q58cH2A8mjSDA3vaS3pa6clroKjqur4Lj6CmZVldE/OEzv4DD9gyP0Dg7TNzjM4PAIdZWlzKoqo6GqjNnVpcyuKqOhuszJxvLKCcJsHMVF4viGpNloPKXFRWNuNzA0wqZdSbJ4eMc+nuzsYfvePh7c1s3ND3XQMzB8xPHVlpfQnCaalroKmuuSvpTK0mKGIxgZCYZGnnosLkqSYk15CdXlJVSXFVNdXsLsqjIWzK6kyFeCWQYnCLM8Kysp4uSWWk5ueWYHSkTQ3T/Ejr197O0dpKK0OF2KqCwtprKsmJKiIrr6BtnTM0Dn/kE69z/VB9LR3c+Orj52dPXxu8c6ae/uy9oklovaihJOm1/P6QtmccaCek5bUM/8WZVP67CPCPqHRhgYHqFvYJj9A8Ps7x+iZ2CY/QND9A4MU1IkmusqaE4vAvCAjlOXE4RZAUmirqKUukNcfjunppw5NeWHPF5EsLtnkP6hYYqLRLFESVERRUVQUlTEcAQ9/clVYPv7h9nXP0TPwBDt3f3cv2Uv927ey1du33ggydRXllJSpCQppInhcDVUl9FcW05zXQXzDhqna+6sCuorS3l8Vw8bO/axced+Hm1PHp/s7GFufQUnt9Ty7ONqOfm45HFxYzUlxUUHklXPQNIs1zswRJGU9A1VlLo2dAw4QZhNI0o/IMdTU15C8zjr+waHeWh7N/du3sOD27uBpBZUXlKcPiZLZVkx1WUlBx6ryoupKitmYGiE9q5+2rv7ae/uSx67kufrtnaxc5z50EuKxKLGKpY21fD8k5rY3tXLg9u7+eX6HYxeA1BWXERpsegdHGas2XKLi8Tsqqf6auorSw/UzMpLnnosLS5icDhJfP2Dw/QPjdA/NMLg8Agrjp/FS0897pDNi9OZx2IyswnVPzTM9r19bN3Tx7a9vezpGWRhQxVLm6o5vqEqa5NU3+AwG9r38fCObh7a0c3gUFBVljTBVaVLZVkJwyMjaTNc/4HH3fsH2dub1Kr6BkfoH0oSQV+aYIoE5SXFlJcWUVZcRHlpERGweXcvAMvn13HRqcdx0fLjODG9zjoi6OjuZ0P7Ph7t2MejHfvZ0zNAZVkxlaUlT4utuqyE+qpSZlU+dZFDfVUp5SXFDA2P0N03RFffIF29yT093f1DLJlTzYlNNRNSC/Jw32ZmB4kIRoIxh2h5fNd+fv7Adn52/3buemIPACc0VVNTUcrG9n10Z9xDU1NewuzqUnoHksTTMzA0Zu1mVFlx0bhNdrOrSmld3MDZ6Xzxy+Zmnys+IrkA4Uj7epwgzMyOwva9faxet51frNvB8EgcuKdl9PHgOU9G+0d6B5J+nr29SS1mT88gu3uSGyy7+gapLiuhtqIk6YeqLKW2Iql9PLS9m9891smdmzrZtKsHSOaKb66roH9wOGkSS/uF+odGaK4t53cfvvCIzs0Jwsxsihq9Qu3OTZ3s7hk80AxWVvxUf1BdZSlvPW/pER3fw32bmU1RLXUVvOKMebzijHkT/t6+QNnMzLLKa4KQdJGkhyRtkPSBLOvfJ2mdpHsl3ShpUca6YUl3p8t1+YzTzMyeKW9NTJKKgc8DLwY2A3dKui4i1mVs9nugNSJ6JL0d+BTwunRdb0SsyFd8ZmY2vnzWIFYCGyJiY0QMAN8GXpW5QUTcFBE96cs1wII8xmNmZochnwliPvBkxuvNadlY3gL8NON1haQ2SWsk/fFYO0m6LN2uraOj4+giNjOzAybFVUySLgFagfMzihdFxBZJS4FfSbovIh49eN+IuAq4CpLLXCckYDOzGSCfNYgtwPEZrxekZU8j6ULgw8ArI+LAIC0RsSV93AjcDDwnj7GamdlB8pkg7gROkrREUhnweuBpVyNJeg7wJZLk0J5RPltSefp8DvA8ILNz28zM8iyvd1JL+kPgSqAYuDoiPiHpCqAtIq6T9EvgNGBbussTEfFKSeeQJI4RkiR2ZUR8JYf36wAeP8Jw5wA7j3DfqcznPbP4vGeWXM57UUQ0ZVsxrYbaOBqS2sa63Xw683nPLD7vmeVoz9t3UpuZWVZOEGZmlpUTxFOuKnQABeLznll83jPLUZ23+yDMzCwr1yDMzCwrJwgzM8tqxieIQw1JPp1IulpSu6T7M8oaJK2W9Ej6OLuQMR5rko6XdFM6rPwDkt6Tlk/r8waQVCHpd5LuSc/9Y2n5Ekl3pH/z30lvZJ1WJBVL+r2k69PX0/6cASRtknRfOk1CW1p2xH/rMzpBZAxJ/jJgGXCxpGWFjSqvvgpcdFDZB4AbI+Ik4Mb09XQyBLw/IpYBq4B3pL/j6X7eAP3ACyPiDGAFcJGkVcA/AZ+JiBOB3SQDZU437wHWZ7yeCec86gURsSLj/ocj/luf0QmCHIYkn04i4lag86DiVwFfS59/DRhz5NypKCK2RcRd6fNukg+N+Uzz8waIxL70ZWm6BPBC4Ptp+bQ7d0kLgD8Cvpy+FtP8nA/hiP/WZ3qCONwhyaejlogYHepkO9BSyGDySdJikkEf72CGnHfa1HI30A6sBh4F9kTEULrJdPybvxL4W5KhegAamf7nPCqAX0haK+mytOyI/9YnxXDfNjlEREialtc9S6oBfgC8NyK6ki+Viel83hExDKyQNAu4Fnh2gUPKK0kvB9ojYq2kCwodTwGcm06T0AyslvRg5srD/Vuf6TWInIYkn+Z2SJoLkD62H2L7KUdSKUly+GZE/DAtnvbnnSki9gA3Ac8FZkka/XI43f7mnwe8UtImkibjFwKfZXqf8wEZ0yS0k3whWMlR/K3P9ARxyCHJZ4DrgEvT55cCPypgLMdc2v78FWB9RHw6Y9W0Pm8ASU1pzQFJlSTzw68nSRR/mm42rc49Ij4YEQsiYjHJ//OvIuKNTONzHiWpWlLt6HPgJcD9HMXf+oy/kzrbkOQFDilvJF0DXEAyBPAO4HLgf4DvAgtJhkp/bUQc3JE9ZUk6F7gNuI+n2qQ/RNIPMW3PG0DS6SSdksUkXwa/GxFXpLM0fhtoAH4PXJI5Wdd0kTYx/U1EvHwmnHN6jtemL0uAb6VTLDRyhH/rMz5BmJlZdjO9icnMzMbgBGFmZlk5QZiZWVZOEGZmlpUThJmZZeUEYTYJSLpgdORRs8nCCcLMzLJygjA7DJIuSedYuFvSl9LB8PZJ+kw658KNkprSbVdIWiPpXknXjo7DL+lESb9M52m4S9IJ6eFrJH1f0oOSvqnMAaPMCsAJwixHkk4BXgc8LyJWAMPAG4FqoC0iTgVuIblDHeDrwN9FxOkkd3KPln8T+Hw6T8M5wOhIm88B3ksyN8lSknGFzArGo7ma5e5FwFnAnemX+0qSgc9GgO+k23wD+KGkemBWRNySln8N+F46Vs78iLgWICL6ANLj/S4iNqev7wYWA7fn/7TMsnOCMMudgK9FxAefVij9/UHbHen4NZljAw3j/08rMDcxmeXuRuBP07H2R+f6XUTyfzQ6UugbgNsjYi+wW9J5afmbgFvSWe02S/rj9Bjlkqom9CzMcuRvKGY5ioh1kj5CMmNXETAIvAPYD6xM17WT9FNAMrTyF9MEsBH4i7T8TcCXJF2RHuPPJvA0zHLm0VzNjpKkfRFRU+g4zI41NzGZmVlWrkGYmVlWrkGYmVlWThBmZpaVE4SZmWXlBGFmZlk5QZiZWVb/H+W91IYTJIn5AAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## Acknowledgement\n","I collaberated with Yicheng Zou and Max (Yang) Hu to finish this assignment. \n","\n","The code to train ResNet on CIFAR 10 is adapted from GitHub: https://github.com/kuangliu/pytorch-cifar"],"metadata":{"id":"g8q_UOr8SyFS"}}]}